{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, NamedTuple, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../results/processed_data.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantStats(NamedTuple):\n",
    "    user_id: str\n",
    "    total_trials: int\n",
    "    correct_black: int\n",
    "    total_black: int\n",
    "    correct_red: int\n",
    "    total_red: int\n",
    "    avg_rt_fast: float\n",
    "    avg_rt_slow: float\n",
    "    correct_fast: int\n",
    "    total_fast: int\n",
    "    correct_slow: int\n",
    "    total_slow: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_participant_stats(df: pd.DataFrame) -> Dict[str, ParticipantStats]:\n",
    "    \"\"\"Calculate statistics for each participant.\"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    for user_id in df['user_id'].unique():\n",
    "        user_data = df[df['user_id'] == user_id]\n",
    "        \n",
    "        # Calculate color-based stats\n",
    "        black_trials = user_data[user_data['arrow_color'] == 'black']\n",
    "        red_trials = user_data[user_data['arrow_color'] == 'red']\n",
    "        \n",
    "        # Calculate speed-based stats\n",
    "        fast_trials = user_data[user_data['speed_group'].str.contains('Fast')]\n",
    "        slow_trials = user_data[user_data['speed_group'].str.contains('Slow')]\n",
    "        \n",
    "        stats[user_id] = ParticipantStats(\n",
    "            user_id=user_id,\n",
    "            total_trials=len(user_data),\n",
    "            correct_black=len(black_trials[black_trials['is_correct']]),\n",
    "            total_black=len(black_trials),\n",
    "            correct_red=len(red_trials[red_trials['is_correct']]),\n",
    "            total_red=len(red_trials),\n",
    "            avg_rt_fast=fast_trials['response_time'].mean(),\n",
    "            avg_rt_slow=slow_trials['response_time'].mean(),\n",
    "            correct_fast=len(fast_trials[fast_trials['is_correct']]),\n",
    "            total_fast=len(fast_trials),\n",
    "            correct_slow=len(slow_trials[slow_trials['is_correct']]),\n",
    "            total_slow=len(slow_trials)\n",
    "        )\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_visualization(stats: Dict[str, ParticipantStats]) -> None:\n",
    "    \"\"\"Create a visualization comparing fast vs slow performance.\"\"\"\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    \n",
    "    for stat in stats.values():\n",
    "        # Only include data points where trials exist\n",
    "        if stat.total_fast > 0:\n",
    "            plot_data.append({\n",
    "                'user_id': stat.user_id,\n",
    "                'Speed': 'Fast',\n",
    "                'Accuracy (%)': (stat.correct_fast / stat.total_fast * 100)\n",
    "            })\n",
    "        if stat.total_slow > 0:\n",
    "            plot_data.append({\n",
    "                'user_id': stat.user_id,\n",
    "                'Speed': 'Slow',\n",
    "                'Accuracy (%)': (stat.correct_slow / stat.total_slow * 100)\n",
    "            })\n",
    "    \n",
    "    plot_data = pd.DataFrame(plot_data)\n",
    "    \n",
    "    if len(plot_data) == 0:\n",
    "        print(\"Warning: No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Create box plot with individual points\n",
    "    sns.boxplot(data=plot_data, x='Speed', y='Accuracy (%)', color='lightgray')\n",
    "    sns.swarmplot(data=plot_data, x='Speed', y='Accuracy (%)', color='darkblue', size=8)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Accuracy Comparison: Fast vs Slow Display Times', pad=20)\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    \n",
    "    # Add mean lines for each condition\n",
    "    means = plot_data.groupby('Speed')['Accuracy (%)'].mean()\n",
    "    for i, speed in enumerate(means.index):\n",
    "        plt.hlines(means[speed], i-0.3, i+0.3, color='red', linestyles='dashed', label='Mean' if i == 0 else '')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_trend_visualization(df: pd.DataFrame, users_to_include: list = None) -> None:\n",
    "    \"\"\"\n",
    "    Create a line plot showing accuracy trends over days for selected participants, separated by speed.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "    users_to_include : list, optional\n",
    "        List of user IDs to include in the visualization. If None, includes all users.\n",
    "    \"\"\"\n",
    "    # Filter for specified users if provided\n",
    "    if users_to_include is not None:\n",
    "        df = df[df['user_id'].isin(users_to_include)]\n",
    "        if df.empty:\n",
    "            print(\"No data found for specified users.\")\n",
    "            return\n",
    "    \n",
    "    # Calculate daily accuracy for each participant and speed condition\n",
    "    daily_accuracy = df.groupby(['user_id', 'day', 'speed_group']).agg({\n",
    "        'is_correct': ['count', 'sum']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate accuracy percentage\n",
    "    daily_accuracy.columns = ['user_id', 'day', 'speed_group', 'total_trials', 'correct_trials']\n",
    "    daily_accuracy['accuracy'] = (daily_accuracy['correct_trials'] / \n",
    "                                daily_accuracy['total_trials'] * 100)\n",
    "    \n",
    "    # Simplify speed group names\n",
    "    daily_accuracy['speed'] = daily_accuracy['speed_group'].apply(\n",
    "        lambda x: 'Fast' if 'Fast' in x else 'Slow'\n",
    "    )\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Get unique users for color assignment\n",
    "    users = sorted(df['user_id'].unique())\n",
    "    colors = sns.color_palette(\"husl\", n_colors=len(users))\n",
    "    \n",
    "    # Create line plot for each user and speed condition\n",
    "    for i, user in enumerate(users):\n",
    "        user_data = daily_accuracy[daily_accuracy['user_id'] == user]\n",
    "        \n",
    "        # Plot fast condition (solid line)\n",
    "        fast_data = user_data[user_data['speed'] == 'Fast']\n",
    "        if not fast_data.empty:\n",
    "            plt.plot(fast_data['day'], fast_data['accuracy'], \n",
    "                    color=colors[i], linestyle='-', marker='o',\n",
    "                    label=f'{user} (Fast)', markersize=8)\n",
    "        \n",
    "        # Plot slow condition (dashed line)\n",
    "        slow_data = user_data[user_data['speed'] == 'Slow']\n",
    "        if not slow_data.empty:\n",
    "            plt.plot(slow_data['day'], slow_data['accuracy'], \n",
    "                    color=colors[i], linestyle='--', marker='s',\n",
    "                    label=f'{user} (Slow)', markersize=8)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Accuracy Trends Over Time by Participant and Speed', pad=20)\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    \n",
    "    # Adjust x-axis to show only integer days\n",
    "    plt.xticks(sorted(daily_accuracy['day'].unique()))\n",
    "    \n",
    "    # Add legend with a title\n",
    "    plt.legend(title='Participant ID (Speed)',\n",
    "              bbox_to_anchor=(1.05, 1), \n",
    "              loc='upper left',\n",
    "              borderaxespad=0)\n",
    "    \n",
    "    # Ensure no labels are cut off\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Example usage:\n",
    "# For all users\n",
    "create_accuracy_trend_visualization(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for all participants\n",
    "participant_stats = calculate_participant_stats(results)\n",
    "\n",
    "# Create visualizations\n",
    "create_comparison_visualization(participant_stats)\n",
    "plt.show()\n",
    "\n",
    "create_accuracy_trend_visualization(results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_user_ids(df: pd.DataFrame, \n",
    "                   id_column: str,\n",
    "                   mapping_dict: dict,\n",
    "                   verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remap user IDs in a DataFrame based on a provided mapping dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame containing user IDs to be remapped\n",
    "    id_column : str\n",
    "        The name of the column containing user IDs\n",
    "    mapping_dict : dict\n",
    "        Dictionary mapping incorrect user IDs to their correct versions\n",
    "        e.g., {'old_id1': 'new_id1', 'old_id2': 'new_id2'}\n",
    "    verbose : bool, default=True\n",
    "        If True, prints summary of changes made\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with remapped user IDs\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Keep track of changes for reporting\n",
    "    changes = {}\n",
    "    \n",
    "    # Apply the mapping\n",
    "    for old_id, new_id in mapping_dict.items():\n",
    "        mask = df_clean[id_column] == old_id\n",
    "        count = mask.sum()\n",
    "        if count > 0:\n",
    "            df_clean.loc[mask, id_column] = new_id\n",
    "            changes[old_id] = {'new_id': new_id, 'count': count}\n",
    "    \n",
    "    # Print summary if verbose is True\n",
    "    if verbose and changes:\n",
    "        print(\"\\nUser ID Remapping Summary:\")\n",
    "        print(\"-\" * 50)\n",
    "        for old_id, info in changes.items():\n",
    "            print(f\"Renamed {info['count']} instances of '{old_id}' to '{info['new_id']}'\")\n",
    "        print(f\"\\nUnique user IDs after remapping: {df_clean[id_column].nunique()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "id_mapping = {\n",
    "    'Klow196': 'Klow1964',\n",
    "    'klow_burns': 'Klow1964'\n",
    "}\n",
    "\n",
    "# Apply the remapping\n",
    "results_clean = remap_user_ids(results, \n",
    "                             id_column='user_id', \n",
    "                             mapping_dict=id_mapping)\n",
    "\n",
    "# Optional: Verify the changes\n",
    "print(\"\\nUnique user IDs in cleaned dataset:\")\n",
    "print(sorted(results_clean['user_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_trend_visualization(results_clean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data_sample = results_clean.sample(100)\n",
    "# clean_data_sample.to_csv('../results/clean_data_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def identify_duplicate_trials(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify cases where users answered the same question multiple times in a quiz on the same day.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing duplicate trial entries\n",
    "    \"\"\"\n",
    "    # Count occurrences of each question by each user in each quiz\n",
    "    trial_counts = df.groupby(['user_id', 'day', 'quiz_id', 'image_index']).size().reset_index(name='attempts')\n",
    "    \n",
    "    # Filter for cases with multiple attempts\n",
    "    duplicates = trial_counts[trial_counts['attempts'] > 1]\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"\\nFound {len(duplicates)} instances of duplicate trial attempts:\")\n",
    "        for _, row in duplicates.iterrows():\n",
    "            print(f\"User {row['user_id']} attempted question {row['image_index']} \"\n",
    "                  f\"in quiz {row['quiz_id']} on day {row['day']} {row['attempts']} times\")\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "def identify_incomplete_quizzes(df: pd.DataFrame, expected_trials: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify quizzes where users didn't complete all trials.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "    expected_trials : int\n",
    "        Expected number of trials per quiz\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing incomplete quiz information\n",
    "    \"\"\"\n",
    "    # Count trials per quiz for each user\n",
    "    trial_counts = df.groupby(['user_id', 'day', 'quiz_id']).agg(\n",
    "        unique_trials=('image_index', 'nunique'),\n",
    "        total_trials=('image_index', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Identify incomplete quizzes or quizzes with duplicate trials\n",
    "    incomplete = trial_counts[\n",
    "        (trial_counts['unique_trials'] != expected_trials) | \n",
    "        (trial_counts['total_trials'] != expected_trials)\n",
    "    ]\n",
    "    \n",
    "    if len(incomplete) > 0:\n",
    "        print(f\"\\nFound {len(incomplete)} problematic quizzes:\")\n",
    "        for _, row in incomplete.iterrows():\n",
    "            if row['unique_trials'] != row['total_trials']:\n",
    "                print(f\"User {row['user_id']} quiz {row['quiz_id']} day {row['day']}: \"\n",
    "                      f\"{row['unique_trials']} unique trials, {row['total_trials']} total trials \"\n",
    "                      f\"(indicates duplicate questions)\")\n",
    "            else:\n",
    "                print(f\"User {row['user_id']} quiz {row['quiz_id']} day {row['day']}: \"\n",
    "                      f\"completed {row['unique_trials']}/{expected_trials} trials\")\n",
    "    \n",
    "    return incomplete\n",
    "\n",
    "def check_data_quality(df: pd.DataFrame, expected_trials: int = 48) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run all data quality checks and return results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "    expected_trials : int, default=48\n",
    "        Expected number of trials per quiz\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "        Duplicate trials DataFrame, Incomplete quizzes DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"Running data quality checks (expected {expected_trials} trials per quiz)...\")\n",
    "    \n",
    "    duplicates = identify_duplicate_trials(df)\n",
    "    incomplete = identify_incomplete_quizzes(df, expected_trials)\n",
    "    \n",
    "    # Get detailed information about specific cases\n",
    "    if len(duplicates) > 0:\n",
    "        print(\"\\nDetailed information for duplicate trials:\")\n",
    "        for _, dup in duplicates.iterrows():\n",
    "            relevant_trials = df[\n",
    "                (df['user_id'] == dup['user_id']) & \n",
    "                (df['day'] == dup['day']) & \n",
    "                (df['quiz_id'] == dup['quiz_id']) &\n",
    "                (df['image_index'] == dup['image_index'])\n",
    "            ]\n",
    "            print(f\"\\nDetailed trials for duplicate question {dup['image_index']} \"\n",
    "                  f\"by {dup['user_id']} on day {dup['day']} quiz {dup['quiz_id']}:\")\n",
    "            print(relevant_trials[['timestamp', 'image_index', 'user_answer', 'is_correct']].sort_values('timestamp'))\n",
    "    \n",
    "    return duplicates, incomplete\n",
    "\n",
    "# Example usage\n",
    "# Check with default 48 trials\n",
    "# duplicates, incomplete = check_data_quality(results)\n",
    "\n",
    "# Or specify a different number of expected trials\n",
    "duplicates, incomplete = check_data_quality(results_clean, expected_trials=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_trials(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicate trials from the dataset, keeping only the first instance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "    verbose : bool, default=True\n",
    "        If True, prints summary of removed duplicates\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned DataFrame with duplicates removed\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Sort by timestamp to ensure we keep the first instance\n",
    "    df_clean = df_clean.sort_values('timestamp')\n",
    "    \n",
    "    # Count initial trials\n",
    "    initial_count = len(df_clean)\n",
    "    \n",
    "    # Drop duplicates based on user_id, day, quiz_id, and image_index\n",
    "    df_clean = df_clean.drop_duplicates(\n",
    "        subset=['user_id', 'day', 'quiz_id', 'image_index'],\n",
    "        keep='first'\n",
    "    )\n",
    "    \n",
    "    # Count removed trials\n",
    "    removed_count = initial_count - len(df_clean)\n",
    "    \n",
    "    if verbose and removed_count > 0:\n",
    "        print(f\"\\nRemoved {removed_count} duplicate trials:\")\n",
    "        print(f\"Initial trial count: {initial_count}\")\n",
    "        print(f\"Final trial count: {len(df_clean)}\")\n",
    "        \n",
    "        # Get counts by user\n",
    "        user_counts = df.groupby('user_id').size() - df_clean.groupby('user_id').size()\n",
    "        users_with_duplicates = user_counts[user_counts > 0]\n",
    "        \n",
    "        print(\"\\nDuplicates removed by user:\")\n",
    "        for user, count in users_with_duplicates.items():\n",
    "            print(f\"{user}: {count} duplicate trials removed\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_and_validate_data(df: pd.DataFrame, expected_trials: int = 48) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean data by removing duplicates and validate the results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "    expected_trials : int, default=48\n",
    "        Expected number of trials per quiz\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    print(\"Starting data cleaning process...\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_clean = remove_duplicate_trials(df)\n",
    "    \n",
    "    # Validate results\n",
    "    print(\"\\nValidating cleaned data...\")\n",
    "    duplicates, incomplete = check_data_quality(df_clean, expected_trials)\n",
    "    \n",
    "    if len(duplicates) == 0:\n",
    "        print(\"\\nAll duplicates successfully removed!\")\n",
    "    else:\n",
    "        print(\"\\nWarning: Some duplicates remain after cleaning!\")\n",
    "    \n",
    "    # Check if any quizzes are now incomplete due to duplicate removal\n",
    "    if len(incomplete) > 0:\n",
    "        print(\"\\nNote: Some quizzes are incomplete after duplicate removal.\")\n",
    "        print(\"You may want to handle these cases separately.\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Example usage\n",
    "# Clean the data\n",
    "results_drop_dups = clean_and_validate_data(results_clean, expected_trials=50)\n",
    "\n",
    "# Optional: Compare trial counts before and after cleaning\n",
    "print(\"\\nTrial counts by user (before cleaning):\")\n",
    "print(results.groupby('user_id').size())\n",
    "print(\"\\nTrial counts by user (after cleaning):\")\n",
    "print(results_drop_dups.groupby('user_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_trend_visualization(results_clean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_trend_visualization(results_drop_dups, users_to_include=['HRB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_quiz_day_assignments(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fix cases where the same quiz appears on multiple days by properly separating and \n",
    "    reassigning quiz numbers to maintain sequential ordering.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the experiment data\n",
    "    verbose : bool, default=True\n",
    "        If True, prints details about corrections made\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with corrected quiz assignments\n",
    "    \"\"\"\n",
    "    df_fixed = df.copy()\n",
    "    \n",
    "    # Process each user separately\n",
    "    for user in df_fixed['user_id'].unique():\n",
    "        user_data = df_fixed[df_fixed['user_id'] == user]\n",
    "        \n",
    "        # Check for days with more than 2 quizzes or more than 96 trials\n",
    "        problematic_days = user_data.groupby('day').agg({\n",
    "            'quiz_id': ['nunique', 'count']\n",
    "        }).reset_index()\n",
    "        problematic_days.columns = ['day', 'num_quizzes', 'num_trials']\n",
    "        problematic_days = problematic_days[\n",
    "            (problematic_days['num_quizzes'] > 2) | \n",
    "            (problematic_days['num_trials'] > 96)\n",
    "        ]\n",
    "        \n",
    "        if len(problematic_days) > 0 and verbose:\n",
    "            print(f\"\\nProcessing user {user}\")\n",
    "            print(f\"Found {len(problematic_days)} days with incorrect quiz assignments\")\n",
    "        \n",
    "        # Process each problematic day\n",
    "        for _, row in problematic_days.iterrows():\n",
    "            day = row['day']\n",
    "            day_data = user_data[user_data['day'] == day]\n",
    "            \n",
    "            # Get unique quizzes for this day\n",
    "            quizzes = sorted(day_data['quiz_id'].unique())\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nDay {day}: Found {len(quizzes)} quizzes: {quizzes}\")\n",
    "            \n",
    "            # Process each quiz after the first two\n",
    "            for i, quiz_id in enumerate(quizzes[2:], start=2):\n",
    "                # Get trials for this quiz\n",
    "                quiz_trials = day_data[day_data['quiz_id'] == quiz_id]\n",
    "                \n",
    "                # Calculate new day (original day + 1)\n",
    "                new_day = day + 1\n",
    "                \n",
    "                # Calculate new quiz ID (should be max + 1)\n",
    "                new_quiz_id = df_fixed['quiz_id'].max() + 1\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Moving quiz {quiz_id} to day {new_day} with new quiz_id {new_quiz_id}\")\n",
    "                \n",
    "                # Update the trials\n",
    "                mask = (df_fixed['user_id'] == user) & \\\n",
    "                       (df_fixed['day'] == day) & \\\n",
    "                       (df_fixed['quiz_id'] == quiz_id)\n",
    "                \n",
    "                df_fixed.loc[mask, 'day'] = new_day\n",
    "                df_fixed.loc[mask, 'quiz_id'] = new_quiz_id\n",
    "    \n",
    "    # Sort the DataFrame to make it easier to verify\n",
    "    df_fixed = df_fixed.sort_values(['user_id', 'day', 'quiz_id'])\n",
    "    \n",
    "    return df_fixed\n",
    "\n",
    "# Example usage\n",
    "# Fix quiz assignments\n",
    "results_fixed = fix_quiz_day_assignments(results_drop_dups)\n",
    "\n",
    "# Verify the changes\n",
    "def verify_quiz_assignments(df: pd.DataFrame):\n",
    "    \"\"\"Print summary of quiz assignments per user per day.\"\"\"\n",
    "    for user in df['user_id'].unique():\n",
    "        user_data = df[df['user_id'] == user]\n",
    "        quiz_summary = user_data.groupby(['day'])[['quiz_id', 'speed_group']].agg({\n",
    "            'quiz_id': ['count', 'unique'],\n",
    "            'speed_group': 'unique'\n",
    "        }).reset_index()\n",
    "        quiz_summary.columns = ['day', 'total_trials', 'unique_quizzes', 'speeds']\n",
    "        print(f\"\\nUser: {user}\")\n",
    "        print(quiz_summary)\n",
    "\n",
    "# Run verification\n",
    "print(\"\\nVerifying quiz assignments after corrections:\")\n",
    "verify_quiz_assignments(results_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_trend_visualization(results_fixed, users_to_include=['HRB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_accuracy_trend_visualization(results_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fixed.to_csv('../results/cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyc_decompile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
